{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Maximum Likelihood Estimate (MLE)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this lab session we shall have a look at how to use the *Maximum Likelihood Estimate (MLE)* method to estimate the parameters of some model, given some observations $D$.\n",
    "\n",
    "<font color=\"red\">NOTE: </font>In the notation $\\mathcal{N} (\\mu, \\sigma^2)$ $\\mu$ refers to the mean and $\\sigma^2$  the variance, not the standard deviation. The standard deviation is $\\sigma = \\sqrt {\\sigma^2}$, i.e. for $\\mathcal{N}(0.5, 0.25)$, the standard deviation is $\\sigma = 0.5$.\n",
    "\n",
    "As usual, let's import the libraries before we start by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function # to avoid issues between Python 2 and 3 printing\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Necessary to import Axes3D to use `plt.subplots(subplot_kw={'projection': '3d'})`\n",
    "# as this internally sets up matplotlib for 3D projection, without this import you'll \n",
    "# get an error.\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show matplotlib figures inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default we set figures to be 7\"x4\" on a 110 dots per inch (DPI) screen \n",
    "# (adjust DPI if you have a high res screen!)\n",
    "plt.rc('figure', figsize=(7, 4), dpi=110)\n",
    "plt.rc('font', size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MLE recipe\n",
    "\n",
    "Let's suppose you're given $n$ one dimensional data points $D = \\{d_0, d_1, ...,  d_{n-1} \\}$ which you believe follow a normal distribution. In this case, your model has two parameters: $\\mu$ and $\\sigma^2$.\n",
    "\n",
    "Given your data $D$, you wish to find the most likely parameters of the normal distribution.\n",
    "Let's assume the standard deviation ($\\sigma$) is 0.5, now estimate the parameter $\\mu$ of the model (the mean of the normal distribution representing your data). \n",
    "\n",
    "Use the Maximum Likelihood Estimate (MLE) formula to show that $\\mu_{ML} = \\frac{1}{n}\\sum_i d_i$.\n",
    "\n",
    "**Hint**: assuming the data points are independent, we have \n",
    "\n",
    "$$p(D|\\mu) = \\prod_i p(d_i | \\mu) = \\prod_i \\mathcal{N}(d_i|\\mu, \\sigma^2)$$\n",
    "\n",
    "Additionally, since this is a convex function, we can analytically find the stationary point that maximises the function where $\\frac{dp(D|\\mu)}{d\\mu} = 0$.\n",
    "\n",
    "**Note:** This should be done on paper (and ideally typed up in $\\LaTeX$ in the cell below), not using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write here your answer using latex notation. Alternatively, write your solution on paper and show it to a TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "L({\\mu}) = \\sum_i log P(d_i|{\\mu})\n",
    "= \\sum_i log {N}(d_i | {\\mu}, \\sigma^2)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLE with Python\n",
    "\n",
    "We know want you to write a simple program that calculates $\\mu_{\\text{ML}}$ using Python.\n",
    "\n",
    "Let's now load the data from the file `data1.dat` and let's plot the histogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "data = np.loadtxt(\"data1.dat\", delimiter = ',')\n",
    "plt.hist(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a histogram approximating a normal distribution. In fact, `data1.data` contains the observations $D$ we talked about above when deriving $\\mu_\\text{ML}$, which we said we believe follows a normal distribution. \n",
    "\n",
    "Write a function `compute_likelihood(D, mu)` that takes a value of $\\mu$ and computes $p(D | \\mu)$ for the data in `data1.dat`, assuming $\\sigma=0.5$.\n",
    "\n",
    "You may use NumPy's function `np.prod` for the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "def compute_likelihood(D, mu):\n",
    "    normals = np.empty(0)\n",
    "    for d_i in D:\n",
    "        normals = np.append(normals, stats.norm.pdf(d_i, mu, 0.5))\n",
    "        \n",
    "    prob = np.prod(normals)\n",
    "    return prob\n",
    "\n",
    "print(compute_likelihood(data, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `loop_likelihood(D)` that calls `compute_likelihood` for each value of $\\mu \\in \\{0.00, 0.01, 0.02, \\ldots , 1.00\\}$, storing *both* the value of $\\mu$ and the corresponding obtained likelihood in a 2D array so that the first column contains the value $\\mu$ and the second the likelihood $p(D|\\mu)$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "def loop_likelihood(D):\n",
    "    means = np.linspace(0, 1, 101)\n",
    "    likelihoods = []\n",
    "    for mu in means:\n",
    "        newlikelihood = [mu, compute_likelihood(D, mu)]\n",
    "        likelihoods.append(newlikelihood)\n",
    "    \n",
    "    return np.array(likelihoods)\n",
    "        \n",
    "likelihoods = loop_likelihood(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- What is the value of the maximum likelihood $\\text{ML} = \\max p(D|\\mu)$ ? \n",
    "\n",
    "- What is $\\mu_{\\text{ML}} = arg\\,max_\\mu \\, p(D|\\mu)$? \n",
    "\n",
    "Make sure you understand the difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "max_index = np.argmax(likelihoods[:,1])\n",
    "mu_ML = likelihoods[max_index][0]\n",
    "max_likelihood = likelihoods[max_index][1]\n",
    "print(mu_ML, max_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual interpretation\n",
    "\n",
    "Look at the obtained $\\mu_{\\text{ML}}$ and at the previously plotted histogram. Can you see any relationship between the obtained value and the histogram?\n",
    "\n",
    "It looks like the middle of the histogram i.e. the mean\n",
    "\n",
    "Let's now plot $\\mu$ against $p(D|\\mu)$, using the $\\mu$ values you used to compute the likelihoods. Plot also a vertical line located at $\\mu_{\\text{ML}}$. Where does this line lie? Is it a meaningful position?\n",
    "\n",
    "It intercepts the plot where the gradient is 0 (so the maximum value of p(D|\\mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(likelihoods[:,0], likelihoods[:,1])\n",
    "ax.axvline(x=mu_ML, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with MLE recipe\n",
    "\n",
    "Now implement the MLE recipe for $\\mu_\\text{ML}$ you solved at the beginning of this sheet to find the value of $\\mu_{ML}$ (note that this should be just one line of code!).\n",
    "\n",
    "Compare this value with that obtained previously. Do the values match? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_MLE = np.sum(data)/len(data)\n",
    "print(mu_MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are very similar. They are the same to 2dp, which makes sense as in the code we only had mu to 2dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Posterior probability\n",
    "\n",
    "Let's suppose now we have some prior knowledge regarding our parameter $\\mu$. More precisely, our belief is that the probability density function (pdf) $p(\\mu)$ modelling our parameter is also given by a normal distribution.\n",
    "\n",
    "Assuming that $\\mu \\sim \\mathcal{N}(0.5,0.01)$, write two functions, `compute_posterior(D, mu)` and `loop_posterior(D)`, to find $\\mu_{\\text{MAP}} = \\arg \\max_{\\mu} p(D|\\mu)p(\\mu)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "def compute_posterior(D, mu):\n",
    "    posterior = compute_likelihood(D, mu) * stats.norm.pdf(mu, 0.5, 0.1)\n",
    "    return posterior\n",
    "\n",
    "def loop_posterior(D):\n",
    "    means = np.linspace(0, 1, 101)\n",
    "    posteriors = []\n",
    "    for mu in means:\n",
    "        posteriors.append([mu, compute_posterior(D, mu)])\n",
    "    return np.array(posteriors)\n",
    "\n",
    "posteriors = loop_posterior(data)\n",
    "max_index = np.argmax(posteriors[:,1])\n",
    "mu_MAP = posteriors[max_index][0]\n",
    "print(mu_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual interpretation\n",
    "\n",
    "\n",
    "Now plot $\\mu$ against both $p(D|\\mu)$ and $p(D|\\mu)p(\\mu)$ similar to the graph below.\n",
    "![MLE](mle.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "fig, ax = plt.subplots()\n",
    "means = np.linspace(0, 1, 101)\n",
    "ax.plot(likelihoods[:,0], likelihoods[:,1], c='r', linestyle = 'dashed', label=\"P(D|mu)\")\n",
    "ax.plot(posteriors[:,0], posteriors[:,1], label=\"P(D|mu)P(mu)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat now the above calculations for `data2.dat` and `data3.dat`. \n",
    "\n",
    "For both files, plot $\\mu$ against both $p(D|\\mu)$ and $p(D|\\mu)p(\\mu)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "data2 = np.loadtxt(\"data2.dat\", delimiter=',')\n",
    "#data3 = np.loadtxt(\"data3.dat\", delimiter=',')\n",
    "likelihoods2 = loop_likelihood(data2)\n",
    "#likelihoods3 = loop_likelihood(data3)\n",
    "posteriors2 = loop_posterior(data2)\n",
    "#posteriors3 = loop_posterior(data3)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(likelihoods2[:,0], likelihoods2[:,1], label='P(D|mu)')\n",
    "ax1.plot(posteriors2[:,0], posteriors2[:,1], label='P(D|mu)P(mu)')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Observe the results obtained on `data2` and `data3`. What can we tell by looking at the figures you plotted above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRECT ANSWER\n",
    "\n",
    "When the likelihood is further from the suggested prior, we are less confident about our measurements, and thus we observe a larger distance between the two distributions' mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA 1\n",
    "\n",
    "Until now, you assumed that our data was generated from a normal distribution with $\\sigma^2 = 0.25$. \n",
    "\n",
    "Remove this assumption and estimate $\\theta_{\\text{MAP}} = [\\mu_{\\text{MAP}}, \\sigma_{\\text{MAP}}]$ experimentally by looping through different values of $\\mu$ and $\\sigma$. \n",
    "\n",
    "Assume the pdf $p(\\sigma)$ is given by $\\mathcal{N}(0.5, 0.16)$.\n",
    "\n",
    "You may need to use `np.nanargmax` instead of `np.argmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "means = np.linspace(0, 1, 101)\n",
    "sigmas = np.linspace(0, 1, 101)\n",
    "\n",
    "def compute_likelihood2(D, mu, sigma):\n",
    "    normals = np.empty(0)\n",
    "    for d_i in D:\n",
    "        normals = np.append(normals, stats.norm.pdf(d_i, mu, sigma))\n",
    "        \n",
    "    prob = np.prod(normals)\n",
    "    return prob\n",
    "\n",
    "def compute_posterior2(D, mu, sigma):\n",
    "    posterior = compute_likelihood(D, mu) * stats.norm.pdf(mu, 0.5, 0.1) * stats.norm.pdf(sigma, 0.5, 0.4)\n",
    "    return posterior\n",
    "    \n",
    "def loop_posterior2(D):\n",
    "    #thetas = np.meshgrid(means, sigmas)\n",
    "    posteriors = []\n",
    "    #print(\"b\")\n",
    "    for mu in means:\n",
    "        for sigma in sigmas:\n",
    "            #print(\"a\")\n",
    "            posteriors.append([mu, sigma, compute_posterior2(D, mu, sigma)])\n",
    "            \n",
    "        \n",
    "    return np.array(posteriors)\n",
    "\n",
    "print(\"a\")\n",
    "posteriors2 = loop_posterior2(data)\n",
    "index = np.argmax(posteriors2[:,2])\n",
    "print(\"b\")\n",
    "print(posteriors2[index][0], posteriors2[index][1])\n",
    "#print(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA 2\n",
    "\n",
    "Plot ($\\mu$, $\\sigma$) against $p(D|\\theta)p(\\theta)$ similar to the mesh graph below (use the function `Axes3D.plot_surface`).\n",
    "![MLE mesh](mle2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "length = len(posteriors2[:,0])\n",
    "shape = (1, length)\n",
    "X = np.array(posteriors2[:,0])\n",
    "Y = np.array(posteriors2[:,1])\n",
    "Z = np.array(posteriors2[:,2])\n",
    "print(X.shape)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "#ax.plot_trisurf(X, Y, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
