{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "from ipywidgets import FloatSlider, IntSlider, interact, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\bracket}[3]{\\left#1 #3 \\right#2}\n",
    "\\newcommand{\\b}{\\bracket{(}{)}}\n",
    "\\newcommand{\\Bernoulli}{{\\rm Bernoulli}\\b}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\X}{\\mathbf{X}}\n",
    "\\newcommand{\\m}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\P}{{\\rm P}\\b}\n",
    "\\newcommand{\\dd}[2][]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\S}{\\mathbf{\\Sigma}}\n",
    "\\newcommand{\\Sh}{\\mathbf{\\hat{\\Sigma}}}\n",
    "\\newcommand{\\mh}{\\boldsymbol{\\hat{\\mu}}}\n",
    "\\newcommand{\\N}{\\mathcal{N}\\b}\n",
    "\\newcommand{\\det}{\\bracket{\\lvert}{\\rvert}}\n",
    "\\newcommand{\\sb}{\\bracket{[}{]}}\n",
    "\\newcommand{\\E}{\\mathbb{E}\\sb}\n",
    "\\newcommand{\\Var}{{\\rm Var}\\sb}\n",
    "\\newcommand{\\Cov}{{\\rm Cov}\\sb}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\newcommand{\\ph}{\\hat{p}}\n",
    "\\newcommand{\\at}{\\bracket{.}{\\rvert}}\n",
    "\\newcommand{\\w}{\\mathbf{w}}\n",
    "\\newcommand{\\W}{\\mathbf{W}}\n",
    "\\newcommand{\\W}{\\mathbf{W}}\n",
    "\\newcommand{\\Wh}{\\mathbf{\\hat{W}}}\n",
    "\\newcommand{\\Y}{\\mathbf{Y}}\n",
    "\\newcommand{\\L}{\\mathcal{L}}\n",
    "\\newcommand{\\wh}{\\mathbf{\\hat{w}}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\0}{\\mathbf{0}}\n",
    "\\newcommand{\\I}{\\mathbf{I}}\n",
    "\\newcommand{\\La}{\\mathbf{\\Lambda}}\n",
    "$$\n",
    "\n",
    "<h1> Part 3: Overfitting, regularisation and cross-validation </h1>\n",
    "\n",
    "<h2> Varieties of overfitting </h2>\n",
    "\n",
    "<h3> Too little data </h3>\n",
    "If we have too little data, then our inferences can be very wrong, even with a simple (correct) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(X):\n",
    "    return t.cat([X, t.ones(X.shape[0], 1)], 1)\n",
    "def fit_Wh(X, Y):\n",
    "    return t.inverse(X.T @ X) @ X.T @ Y\n",
    "\n",
    "def plot():\n",
    "    N     = 3   # number of datapoints\n",
    "    D     = 1   # dimension of datapoints\n",
    "    sigma = 0.5 # output noise\n",
    "    X     = t.tensor([[-0.1], [0], [0.1]])\n",
    "    Xe    = bias(X)\n",
    "    Wtrue = t.tensor([[2.], [-1]])\n",
    "    Y     = Xe @ Wtrue + sigma*t.randn(N, 1)\n",
    "    Wh    = fit_Wh(Xe, Y)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel(\"$x_\\lambda$\")\n",
    "    ax.set_ylabel(\"$y_\\lambda$\")\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.scatter(X, Y, label=\"data\");\n",
    "\n",
    "    xs = t.linspace(-4, 4, 100)[:, None]\n",
    "    ax.plot(xs, bias(xs)@Wtrue, 'b', label=\"true line\")\n",
    "    ax.plot(xs, bias(xs)@Wh, 'r', label=\"fitted\")\n",
    "    ax.legend()\n",
    "    \n",
    "interact_manual(plot);\n",
    "\n",
    "#some fairly reasonable, using red line in vicinity of the data would give\n",
    "#resonable answer\n",
    "\n",
    "#but for some data sets the noise happens to make the line look like it's \n",
    "#going in a totally different direction\n",
    "\n",
    "#don't believe a model fitted using only 3 data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Too little data in some directions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    N     = 100   # number of datapoints\n",
    "    D     = 2   # dimension of datapoints\n",
    "    sigma = 0.5 # output noise\n",
    "    rand = t.randn(N, 1) #1D gaussian random noise\n",
    "    #actual input features\n",
    "    #in X space, data forms a straight line with a little bit of noise\n",
    "    X     = t.cat([rand, -rand], 1) + 1E-3*t.randn(N, 2) \n",
    "    Wtrue = t.tensor([[1.], [-1.]])\n",
    "    Y     = X @ Wtrue + sigma*t.randn(N, 1) #true y's (output)\n",
    "    Wh    = fit_Wh(X, Y)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlabel(\"$x_{\\lambda, 0}$\")\n",
    "    ax.set_ylabel(\"$x_{\\lambda, 1}$\")\n",
    "    ax.set_zlabel(\"$y_{\\lambda, 0}$\")\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.set_zlim(-15, 15)\n",
    "    ax.scatter(X[:, 0], X[:, 1], Y[:, 0])\n",
    "\n",
    "    Xp = t.tensor([\n",
    "        [-4., -4.],\n",
    "        [-4.,  4.],\n",
    "        [ 4., -4.],\n",
    "        [ 4.,  4.]\n",
    "    ])\n",
    "\n",
    "    ax.plot_trisurf(\n",
    "        np.array(Xp[:, 0]), \n",
    "        np.array(Xp[:, 1]), \n",
    "        np.array((Xp @ Wh)[:, 0]), \n",
    "        color='r', \n",
    "        alpha=0.3\n",
    "    )\n",
    "    \n",
    "interact_manual(plot);\n",
    "\n",
    "#generate data such that it lies along a single axis in X-space\n",
    "#good predictions when test data lies on this line - red estimated plane\n",
    "#lies close to true values in region of blue points\n",
    "#but very difficult to estimate what happens to y far away from this line\n",
    "\n",
    "#slightly different noise values gives entirely different plane and predictions\n",
    "# in regions far from data\n",
    "\n",
    "#much more difficult to diagnose\n",
    "#if data has many dimensions, this problem is difficult to establish\n",
    "#use covariance of data in X space\n",
    "#short eigenvector tells us that inputs lie on low-dimensional surface\n",
    "#so could give issues if we try to test outside that region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The function class is too complex </h3>\n",
    "\n",
    "For the sake of argument, we consider \"Chebyshev polynomials\".  These are defined on $-1 \\leq x \\leq 1$ and range from $-1 \\leq y \\leq 1$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cheb(xs, c):\n",
    "    # c is int\n",
    "    coefs = c*[0] + [1]\n",
    "    return np.polynomial.chebyshev.chebval(xs, coefs)\n",
    "\n",
    "xs = np.linspace(-1, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"$x_\\lambda$\")\n",
    "ax.set_ylabel(\"$y_\\lambda$\")\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1.2, 1.2)\n",
    "\n",
    "i = 0\n",
    "def add_line():\n",
    "    global i\n",
    "    ax.plot(xs, cheb(xs, i))\n",
    "    i += 1\n",
    "interact_manual(add_line);\n",
    "\n",
    "#chebyshev polynomials are like polynomials except designed to fit square as well as possible\n",
    "#get increasingly complex\n",
    "#what happens if we try to fit some data using a very high dimensional\n",
    "#feature vector composed of all these complex functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebX(X, order):\n",
    "    assert (-1 <= X).all() and (X <= 1).all()\n",
    "    \n",
    "    xs = []\n",
    "    for c in range(order):\n",
    "        xs.append(cheb(X, c)) #feature vector of size c, contains all chebyshev polys up to that order\n",
    "    return t.cat(xs, 1)\n",
    "   \n",
    "N     = 10  # number of datapoints - risk of overfitting with 10 data points\n",
    "D     = 1   # dimension of datapoints\n",
    "sigma = 0.5 # output noise\n",
    "t.manual_seed(0)\n",
    "rand  = t.rand(N, 1)\n",
    "X     = 2*rand - 1\n",
    "Wtrue = t.tensor([[0.2], [0.5]])\n",
    "Y     = chebX(X, 2) @ Wtrue + sigma*t.randn(N, 1) #2 components of chebyshev poly (bias and linear term)\n",
    "\n",
    "\n",
    "def plot(order):\n",
    "    Xe    = chebX(X, order)\n",
    "    Wh    = fit_Wh(Xe, Y)\n",
    "    print(f\"Wtrue = {Wtrue.T}\")\n",
    "    print(f\"Wh = {Wh.T}\")\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel(\"$x_\\lambda$\")\n",
    "    ax.set_ylabel(\"$y_\\lambda$\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.scatter(X, Y, label=\"data\");\n",
    "\n",
    "    xs = t.linspace(-1, 1, 1000)[:, None]\n",
    "    ax.plot(xs, chebX(xs, order)@Wh, 'r', label=\"fitted\")\n",
    "    ax.legend()\n",
    "    \n",
    "interact_manual(plot, order=IntSlider(min=1, max=10));\n",
    "\n",
    "#at higher orders, the edges get very steep without support from data\n",
    "#extrapolations aren't very sensible\n",
    "\n",
    "#at some point, extrapolations get crazy (and wrong) and the wiggles in the\n",
    "#the middle aren't really supported by data as there is too much noise and\n",
    "#too few data points\n",
    "#trying to base prediction off the higher order models will be very bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Cross-validation </h2>\n",
    "\n",
    "How can we measure overfitting?\n",
    "\n",
    "The standard approach is cross-validation, where we split the data into \"training\" and \"validation\" sets.  We train the model (fit the weights) on the training set, then look at the residuals/errors on the validation set.\n",
    "\n",
    "The model with the smallest cross-validation error wins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:7]\n",
    "X_test = X[7:]\n",
    "\n",
    "Y_train = Y[:7]\n",
    "Y_test = Y[7:]\n",
    "\n",
    "def plot(order):\n",
    "    Wh    = fit_Wh(chebX(X_train, order), Y_train)\n",
    "    \n",
    "    Yh_test = chebX(X_test, order) @ Wh\n",
    "    cross_validation_error = ((Y_test - Yh_test)**2).mean()\n",
    "    print(f\"cross validation error: {cross_validation_error}\")\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel(\"$x_\\lambda$\")\n",
    "    ax.set_ylabel(\"$y_\\lambda$\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.scatter(X_train, Y_train, label=\"training data\");\n",
    "    ax.scatter(X_test, Y_test, label=\"validation data\");\n",
    "    ax.vlines(X_test, Y_test, Yh_test, label=\"test residuals\")\n",
    "    \n",
    "\n",
    "    xs = t.linspace(-1, 1, 1000)[:, None]\n",
    "    ax.plot(xs, chebX(xs, order)@Wh, 'r', label=\"fitted\")\n",
    "    ax.legend()\n",
    "    \n",
    "interact_manual(plot, order=IntSlider(min=1, max=10));\n",
    "\n",
    "#cross validation error is average of the squared errors\n",
    "#linear function is best as it has lowest cross validation error\n",
    "\n",
    "#gives automated way of selecting functions of different complexity\n",
    "#helpful for large data sets with many input features\n",
    "\n",
    "#3 points as validation data. Means cross validation error could be very sensitive\n",
    "#to the choice of these 3 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> k-fold cross-validation </h3>\n",
    "\n",
    "If you have relatively little data (as here), one thing you can do is to split your data up into train/validation sets in multiple different ways.\n",
    "\n",
    "i.e. try different choices of the orange points\n",
    "\n",
    "Split data into k parts, use one part as test/validation data, others as training data\n",
    "\n",
    "Leave one out cross validation - take single data point as validation set, average over all choices of this point (different from k-fold)\n",
    "\n",
    "All of these try to average over different choices of the validation data - more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Regularisation </h2>\n",
    "\n",
    "Cross-validation is great, but what if you've got lots of noise, and you can't control for that by just using a simple linear model?\n",
    "\n",
    "Then, you don't want to give up on using the more complex basis functions to capture non-linearities.\n",
    "\n",
    "Instead, we can penalise the weights, in particular,\n",
    "\n",
    "\\begin{align}\n",
    "  \\L(\\w) &= \\log \\P{\\y| \\X, \\w} - \\tfrac{1}{2} \\w^T \\La \\w\n",
    "\\end{align}\n",
    "\n",
    "where we could (if we wanted) penalise different weights differently, using the diagonal matrix, $\\La$. This matrix is always positive so large weights apply a negative penalty.\n",
    "\n",
    "As an exercise (in problem sheet), the solution of the corresponding optimization problem is,\n",
    "\n",
    "\\begin{align}\n",
    "  \\Wh &= \\b{\\b{\\X^T \\X}^{-1} + \\sigma^2 \\La}^{-1} \\X \\y\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N     = 30  # number of datapoints\n",
    "D     = 1   # dimension of datapoints\n",
    "sigma = 0.2 # output noise\n",
    "t.manual_seed(0)\n",
    "rand  = t.rand(N, 1)\n",
    "X     = 2*rand - 1\n",
    "Wtrue = t.tensor([[0.], [0.], [0.], [0.], [0.3]])\n",
    "Y     = chebX(X, 5) @ Wtrue + sigma*t.randn(N, 1) #chebyshev poly of order 5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"$x_\\lambda$\")\n",
    "ax.set_ylabel(\"$y_\\lambda$\")\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-2, 2)\n",
    "\n",
    "ax.scatter(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:20]\n",
    "X_test = X[20:]\n",
    "\n",
    "Y_train = Y[:20]\n",
    "Y_test = Y[20:]\n",
    "\n",
    "def fit_reg_Wh(X, Y, reg):\n",
    "    # reg = sigma**2 * Lambda\n",
    "    return t.inverse(X.T @ X + reg*t.eye(X.shape[1])) @ X.T @ Y\n",
    "\n",
    "def plot(order, reg):\n",
    "    Wh    = fit_reg_Wh(chebX(X_train, order), Y_train, reg)\n",
    "\n",
    "    Yh_test = chebX(X_test, order) @ Wh\n",
    "    cross_validation_error = ((Y_test - Yh_test)**2).mean()\n",
    "    print(f\"cross validation error: {cross_validation_error}\")\n",
    "    print(f\"Wh: {Wh.T}\")\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel(\"$x_\\lambda$\")\n",
    "    ax.set_ylabel(\"$y_\\lambda$\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.scatter(X_train, Y_train, label=\"training data\");\n",
    "    ax.scatter(X_test, Y_test, label=\"validation data\");\n",
    "    ax.vlines(X_test, Y_test, Yh_test, label=\"test residuals\")\n",
    "    \n",
    "\n",
    "    xs = t.linspace(-1, 1, 1000)[:, None]\n",
    "    ax.plot(xs, chebX(xs, order)@Wh, 'r', label=\"fitted\")\n",
    "    ax.legend()\n",
    "    \n",
    "interact_manual(plot, order=IntSlider(min=1, max=12), reg=FloatSlider(min=0, max=2));\n",
    "\n",
    "#size of regulariser = diagonal values of the lambda\n",
    "#also plotting the estimated weight\n",
    "\n",
    "#when order becomes high, the fitted weights become very large\n",
    "#predicted line can only go to very large values at the edges (overfitting) \n",
    "#if the weights have large values\n",
    "\n",
    "#even with 12th order function, penalising magnitude means the prediction\n",
    "#line isn't going as crazy\n",
    "\n",
    "#still plotting cross validation error\n",
    "#at some value, the regulariser over-penalises weights so cross validation error will get worse\n",
    "#and line gets stuck at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this example, the corollary of overfitting is the estimated weights getting really big.\n",
    "\n",
    "Regularisation explicitly penalises large weights, and gives more sensible solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Automatic selection of the regulariser using cross-validation </h3>\n",
    "\n",
    "Now things are even worse.  Before, we just had to choose the \"function complexity\", which was a smallish integer.  Now we have to choose a regulariser, and we don't even know what type of size the regulariser should be. So now we really need an automatic way of choosing function complexity and regulariser.\n",
    "\n",
    "The only thing we can do is to use cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(order, reg):\n",
    "    Wh    = fit_reg_Wh(chebX(X_train, order), Y_train, reg)\n",
    "\n",
    "    Yh_test = chebX(X_test, order) @ Wh\n",
    "    return ((Y_test - Yh_test)**2).mean()\n",
    "\n",
    "log_10_regs = np.linspace(-4, 4, 100)\n",
    "regs = 10**log_10_regs\n",
    "cv_errors = np.array([cv(10, reg) for reg in regs])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"regulariser\")\n",
    "ax.set_ylabel(\"cross-validation error\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.plot(regs, cv_errors);\n",
    "\n",
    "#plot magnitude of regulariser against cross validation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can select the regulariser with the lowest cross-validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg = regs[np.argmin(cv_errors)]\n",
    "plot(order=10, reg=best_reg)\n",
    "\n",
    "#select regulariser with lowest cross validation error and plot it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Limits of cross-validation </h3>\n",
    "\n",
    "There's a bunch of issues with cross-validation:\n",
    "<ul>\n",
    "    <li> Parameter sweeps can be numerically costly. If data set is large and complex. With many different parameters, number of things to try increases exponentially.</li>\n",
    "    <li> Splitting your data gives you less data for training, which is very problematic with smaller amounts of data. </li>\n",
    "    <li> Scales poorly if you want to cross-validate many different parameters. Number of possible settings increases exponentially.</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
